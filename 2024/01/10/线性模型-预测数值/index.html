<!DOCTYPE html>
<html>
    <head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover" name="viewport" />
  <meta name="robots" content="index, follow">
  <!-- title -->
  
    
  <title>线性模型-预测数值 - Hexo</title>
    
  
  
  <!-- open graph -->
  <meta name="description" content="附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面">
<meta property="og:type" content="article">
<meta property="og:title" content="线性模型-预测数值">
<meta property="og:url" content="https://mixintu.github.io/2024/01/10/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B-%E9%A2%84%E6%B5%8B%E6%95%B0%E5%80%BC/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://mixintu.github.io/images/2024-01-10/001.png">
<meta property="og:image" content="https://mixintu.github.io/images/2024-01-10/002.png">
<meta property="og:image" content="https://mixintu.github.io/images/2024-01-10/003.png">
<meta property="og:image" content="https://mixintu.github.io/images/2024-01-10/004.png">
<meta property="og:image" content="https://mixintu.github.io/images/2024-01-10/005.png">
<meta property="og:image" content="https://mixintu.github.io/images/2024-01-10/006.png">
<meta property="article:published_time" content="2024-01-10T02:11:02.000Z">
<meta property="article:modified_time" content="2024-01-10T06:54:22.706Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://mixintu.github.io/images/2024-01-10/001.png">
  <!-- canonical -->
  
  <link rel="canonical" href="https://mixintu.github.io/2024/01/10/线性模型-预测数值/">
  
  <!-- Favicon -->
  <link rel="shortcut icon" href="/img/favicon.ico">
  <link rel="apple-touch-icon" sizes="180x180" href="/img/apple-touch-icon.png">
  <!-- CSS -->
  
<link rel="stylesheet" href="/css/reset.css">

  
<link rel="stylesheet" href="/css/style.css">

  
<link rel="stylesheet" href="/css/markdown.css">

  
<link rel="stylesheet" href="/css/fonts.css">

<meta name="generator" content="Hexo 7.0.0"></head>

    <body>
        <div class="paper">
            <div class="paper-main">
                
                    <div class="post-header">
    <a class="logo" href="/">Hexo</a>
    <!-- <div class="logo"><a href="/" title="Len"><img src="/img/logo.svg" alt="Len" aria-label="logo" height="20"></a></div> -->
        <ul class="nav">
            
            <li><a href="/">Home</a></li>
            
            <li><a href="/about">About</a></li>
            
            <li><a href="/archives">Archives</a></li>
            
        </ul>


    </a>
</div>

                
                <div class="post-main">
    
        <div class="post-main-title">
            线性模型-预测数值
        </div>
        <div class="post-meta">
            2024-01-10 ｜ 
            
                <a href="/categories/%E9%BB%98%E8%AE%A4%E5%88%86%E7%B1%BB/"># 默认分类</a>
            
        </div>
        <!-- 圆角分类 -->
        <!-- <div class="tags"> -->
            <!--  -->
                <!-- <a href="/categories/%E9%BB%98%E8%AE%A4%E5%88%86%E7%B1%BB/">默认分类</a> -->
            <!--  -->
        <!-- </div> -->
        <div class="post-md">
            <h2 id="当-num-epochs-等于-10-次的训练训练效果"><a href="#当-num-epochs-等于-10-次的训练训练效果" class="headerlink" title="当 num_epochs 等于 10 次的训练训练效果"></a>当 num_epochs 等于 10 次的训练训练效果</h2><p><img src="/../images/2024-01-10/001.png" alt="Alt text"></p>
<p><img src="/../images/2024-01-10/002.png" alt="Alt text"></p>
<p><img src="/../images/2024-01-10/003.png" alt="Alt text"></p>
<h2 id="日志输出"><a href="#日志输出" class="headerlink" title="日志输出"></a>日志输出</h2><details>
<summary><=================== 展开日志输出 ===================></summary><pre><code>
<===========================================================>
&#123;   'CUDA版本号': '12.1',
    'CuDNN版本号': 8801,
    'GPU数量': 1,
    'PyTorch版本号': '2.1.0+cu121',
    'Python版本号': '3.10',
    'Torchvision版本号': '0.16.0+cu121',
    'numpy版本号': '1.24.1',
    '当前CUDA设备': 0,
    '显卡名称': 'NVIDIA GeForce RTX 2080 Ti',
    '检查是否安装了所需的英伟达驱动和CUDA库': True,
    '精度类型': 'highest'&#125;
<===========================================================>
  0%|          | 0/10 [00:00<?, ?it/s]OrderedDict([('linear.weight', tensor([[0.4744]])),
             ('linear.bias', tensor([-0.6016]))])
Epoch 10/10:Loss: 54.27426, Accuracy: 0.00% | Test loss: 51.38795, Test acc: 0.00%: 100%|██████████| 10/10 [00:00<00:00, 96.21it/s]
predict (before training): -->
 tensor([[7.],
        [8.]], device='cuda:0')
predict (after training): -->
 tensor([[ 9.2552],
        [10.6265]], device='cuda:0')
OrderedDict([('linear.weight', tensor([[1.3712]], device='cuda:0')),
             ('linear.bias', tensor([-0.3434], device='cuda:0'))])
</code>
</pre>
</details>




<h2 id="当-num-epochs-等于-100-次的训练训练效果"><a href="#当-num-epochs-等于-100-次的训练训练效果" class="headerlink" title="当 num_epochs 等于 100 次的训练训练效果"></a>当 num_epochs 等于 100 次的训练训练效果</h2><p><img src="/../images/2024-01-10/004.png" alt="Alt text"></p>
<p><img src="/../images/2024-01-10/005.png" alt="Alt text"></p>
<p><img src="/../images/2024-01-10/006.png" alt="Alt text"></p>
<h2 id="日志输出-1"><a href="#日志输出-1" class="headerlink" title="日志输出"></a>日志输出</h2><details>
<summary><=================== 展开日志输出 ===================></summary><pre><code>
<===========================================================>
&#123;   'CUDA版本号': '12.1',
    'CuDNN版本号': 8801,
    'GPU数量': 1,
    'PyTorch版本号': '2.1.0+cu121',
    'Python版本号': '3.10',
    'Torchvision版本号': '0.16.0+cu121',
    'numpy版本号': '1.24.1',
    '当前CUDA设备': 0,
    '显卡名称': 'NVIDIA GeForce RTX 2080 Ti',
    '检查是否安装了所需的英伟达驱动和CUDA库': True,
    '精度类型': 'highest'&#125;
<===========================================================>
OrderedDict([('linear.weight', tensor([[0.4018]])),
             ('linear.bias', tensor([0.4522]))])
Epoch 100/100:Loss: 0.00884, Accuracy: 0.00% | Test loss: 0.00903, Test acc: 0.00%: 100%|██████████| 100/100 [00:00<00:00, 336.73it/s]
predict (before training): -->
 tensor([[7.],
        [8.]], device='cuda:0')
predict (after training): -->
 tensor([[13.9437],
        [15.9234]], device='cuda:0')
OrderedDict([('linear.weight', tensor([[1.9797]], device='cuda:0')),
             ('linear.bias', tensor([0.0855], device='cuda:0'))])
</code>
</pre>
</details>



<h2 id="源代码"><a href="#源代码" class="headerlink" title="源代码"></a>源代码</h2><details>
<summary><=================== 展开源代码 ===================></summary><pre><code>
# %%
import time

<p>import torch</p>
<h1 id=""><a href="#" class="headerlink" title="&lt;- 包含计算图的所有构建块（本质上是以特定方式执行的一系列计算）"></a>&lt;- 包含计算图的所有构建块（本质上是以特定方式执行的一系列计算）</h1><p>import torch.nn as nn</p>
<h1 id="-1"><a href="#-1" class="headerlink" title="&lt;- 包含各种优化算法（这些算法告诉存储在中的模型参数如何最好地更改以改善梯度下降并进而减少损失）"></a>&lt;- 包含各种优化算法（这些算法告诉存储在中的模型参数如何最好地更改以改善梯度下降并进而减少损失）</h1><p>import torch.optim as optim</p>
<h1 id="预加载数据"><a href="#预加载数据" class="headerlink" title="预加载数据"></a>预加载数据</h1><p>from torch.utils.data import DataLoader</p>
<h1 id="-2"><a href="#-2" class="headerlink" title="%%"></a>%%</h1><p>import torchvision<br>from torchvision.transforms import ToTensor<br>from torchvision import datasets, transforms<br>from torchvision.datasets.mnist import MNIST</p>
<h1 id="-3"><a href="#-3" class="headerlink" title="%%"></a>%%</h1><p>import sys<br>import numpy as np<br>import matplotlib.pyplot as plt<br>from pathlib import Path<br>from pprint import pprint<br>from tqdm import tqdm</p>
<p>print(“&lt;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;”)<br>DEVICE &#x3D; torch.device(‘cuda’ if torch.cuda.is_available() else ‘cpu’)<br>pprint(&#123;<br>    “检查是否安装了所需的英伟达驱动和CUDA库”: torch.cuda.is_available(),<br>    “精度类型”: torch.get_float32_matmul_precision(),<br>    “CuDNN版本号”: torch.backends.cudnn.version(),<br>    “显卡名称”: torch.cuda.get_device_name(torch.cuda.current_device()),<br>    “当前CUDA设备”: torch.cuda.current_device(),<br>    “CUDA版本号”: torch.version.cuda,<br>    “GPU数量”: torch.cuda.device_count(),<br>    “PyTorch版本号”: torch.<strong>version</strong>,<br>    “Torchvision版本号”: torchvision.<strong>version</strong>,<br>    “numpy版本号”: np.<strong>version</strong>,<br>    “Python版本号”: sys.winver,<br>&#125;, width&#x3D;50, indent&#x3D;4)<br>print(“&lt;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;”)<br>torch.cuda.empty_cache()  # 清空内存</p>
<h1 id="-4"><a href="#-4" class="headerlink" title="&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;"></a>&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</h1><h1 id="Preprocessing"><a href="#Preprocessing" class="headerlink" title="Preprocessing"></a>Preprocessing</h1><h1 id="-5"><a href="#-5" class="headerlink" title="&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;"></a>&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</h1><p>class LinearRegressionModel(nn.Module):<br>    def <strong>init</strong>(self):<br>        super(LinearRegressionModel, self).<strong>init</strong>()<br>        # 1比1的全连接层<br>        self.linear &#x3D; nn.Linear(in_features&#x3D;1, out_features&#x3D;1, bias&#x3D;True)</p>
<pre><code>def forward(self, x):
    return self.linear(x)
</code></pre>
<p>def accuracy_fn(y_pred, y_true):<br>    # torch.eq() calculates where two tensors are equal<br>    correct &#x3D; torch.eq(y_true, y_pred).sum().item()<br>    return (correct &#x2F; len(y_pred)) * 100</p>
<p>def plot_predictions(x_train,<br>                     y_train,<br>                     x_test,<br>                     y_test,<br>                     predictions&#x3D;None):<br>    “””<br>    Plots training data, test data and compares predictions.<br>    “””<br>    plt.figure(figsize&#x3D;(10, 7))<br>    # Plot training data in blue<br>    plt.scatter(x_train.to(“cpu”), y_train.to(“cpu”), c&#x3D;”b”, s&#x3D;4, label&#x3D;”Training data”)<br>    # Plot test data in green<br>    plt.scatter(x_test.to(“cpu”), y_test.to(“cpu”), c&#x3D;”g”, s&#x3D;4, label&#x3D;”Testing data”)<br>    if predictions is not None:<br>        # Plot the predictions in red (predictions were made on the test data)<br>        plt.scatter(x_test.to(“cpu”), predictions.to(“cpu”), c&#x3D;”r”, s&#x3D;4, label&#x3D;”Predictions”)</p>
<pre><code># Show the legend
plt.legend(prop=&#123;&quot;size&quot;: 14&#125;)
plt.show()
</code></pre>
<p>if <strong>name</strong> &#x3D;&#x3D; ‘<strong>main</strong>‘:<br>    # 准备数据集<br>    X_blob_train &#x3D; torch.Tensor([[1.0], [2.0], [3.0], [4.0], [5.0], [6.0]]).to(DEVICE)<br>    y_blob_train &#x3D; torch.Tensor([[2.0], [4.0], [6.0], [8.0], [10.0], [12.0]]).to(DEVICE)<br>    X_blob_test &#x3D; torch.Tensor([[7.0], [8.0]]).to(DEVICE)<br>    y_blob_test &#x3D; torch.Tensor([[14.0], [16.0]]).to(DEVICE)<br>    plot_predictions(X_blob_train, y_blob_train, X_blob_test, y_blob_test)</p>
<pre><code>network = LinearRegressionModel()
# weight:权重  bias:偏移
pprint(network.state_dict())
# 均方误差（MSE）或 L2 损失【回归】
criterion = nn.MSELoss(reduction=&#39;sum&#39;)
# 随机梯度下降【分类、回归等等】
optimizer = torch.optim.SGD(network.parameters(), lr=0.01)
network.to(DEVICE)

epoch_count = []
train_loss_values = []
test_loss_values = []
num_epochs = 100
for epoch in (bar := tqdm(range(1, num_epochs + 1), position=0)):
    ############
    # Training #
    ############
    network.train()
    # 1、执行前向传递，绕过我们的数据并找出 y 的预测值。
    y_pred_train = network(X_blob_train)
    # 2、使用 MSE 计算损失。
    train_loss = criterion(y_pred_train, y_blob_train)
    train_acc = accuracy_fn(y_pred=y_pred_train, y_true=y_blob_train)
    # 3、Zero grad of the optimizer
    optimizer.zero_grad()  # 清除上一次迭代中的渐变
    # 4. Loss backwards
    train_loss.backward()  # 计算神经元的梯度
    # 5. Progress the optimizer
    optimizer.step()  # 更新权重

    ##############
    # Validation #
    ##############
    network.eval()
    with torch.inference_mode():
        y_pred_test = network(X_blob_test)
        test_loss = criterion(y_pred_test, y_blob_test)
        test_acc = accuracy_fn(y_pred=y_pred_test, y_true=y_blob_test)
        # print(&#39;epoch &#123;&#125;, loss &#123;&#125;&#39;.format(epoch, loss.item()))
        bar.set_description(
            &#39;Epoch &#123;&#125;/&#123;&#125;:Loss: &#123;:.5f&#125;, Accuracy: &#123;:.2f&#125;% | Test loss: &#123;:.5f&#125;, Test acc: &#123;:.2f&#125;%&#39;.format(
                epoch, num_epochs, train_loss, train_acc, test_loss, test_acc
            ))
        # if epoch % 10 == 0:
        epoch_count.append(epoch)
        train_loss_values.append(train_loss.item())
        test_loss_values.append(test_loss.item())

# 预测y_test数据集
network.eval()
new_var = torch.Tensor([[9.0]]).to(DEVICE)
with torch.inference_mode():
    # 预测y_test数据集
    pred_y = network(X_blob_test)
    print(&quot;predict (before training): --&gt;\n&quot;, X_blob_test.detach())
    print(&quot;predict (after training): --&gt;\n&quot;, pred_y.detach())
    pprint(network.state_dict())
    plot_predictions(X_blob_train, y_blob_train, X_blob_test, y_blob_test, pred_y)

plt.plot(epoch_count, train_loss_values, label=&quot;Train loss&quot;)
plt.plot(epoch_count, test_loss_values, label=&quot;Test loss&quot;)
plt.title(&quot;Training and test loss curves&quot;)
plt.ylabel(&quot;Loss&quot;)
plt.xlabel(&quot;Epochs&quot;)
plt.legend()
plt.show()
</code></pre>
</code>
</pre>
</details>
        </div>
    
<!-- tags -->

</div>
                <div class="footer">
    <span>Copyright © 2023 Hexo</span>
    <span>Powered by <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a> with <a target="_blank" rel="noopener" href="https:///imzl.com/zenmind">ZenMind</a></span>
</div>

<link rel="stylesheet" href="/css/a11y-dark.min.css">


<script src="/js/highlight.min.js"></script>


<script src="/js/highlightjs-line-numbers.js"></script>

<script>
    hljs.initHighlightingOnLoad();
    hljs.initLineNumbersOnLoad();
</script>

            </div>
        </div>
    </body>
</html>